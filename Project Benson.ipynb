{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "Assumptions:\n",
    "\n",
    "---\n",
    "\n",
    "Time Constraints:\n",
    "Nonprofit is trying to generate interest for gala happening around the beggining of the summer, we assume street teams would be out canvassing in the three preceding months. March - Mid June.\n",
    "\n",
    "Counter Values: Assume 'entries' and 'exits' columns reflect cumulative counts that could only increase as time moved forward. Thus, we removed any rows with negative values in differential columns and values greater than 100000 (Approximately X% of the rows)\n",
    "\n",
    "Target Metrics:\n",
    "Did not differentiate between entries and exits for a station, but rather relied on 'total_traffic' to determine which station would have the most foot traffic at a given time.\n",
    "\n",
    "Steps:\n",
    "- Read data from turnstile\n",
    "- Preprocess Data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required packages\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads files in turnstile directory into a files list \n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "files = [f for f in listdir('./Data/Turnstile_data') if isfile(join('./Data/Turnstile_data', f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ./Data/Turnstile_data/turnstile_160305.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_160312.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_160319.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_160326.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_160402.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_160409.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_160416.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_160423.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_160430.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_160507.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_160514.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_160521.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_160528.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_160604.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_160611.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_160618.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_170304.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_170311.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_170318.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_170325.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_170401.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_170408.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_170415.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_170422.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_170429.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_170506.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_170513.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_170520.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_170527.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_170603.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_170610.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_170617.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_180303.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_180310.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_180317.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_180324.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_180331.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_180407.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_180414.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_180421.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_180428.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_180505.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_180512.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_180519.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_180526.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_180602.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_180609.txt\n",
      "Loading ./Data/Turnstile_data/turnstile_180616.txt\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9246959 entries, 0 to 196977\n",
      "Data columns (total 11 columns):\n",
      "C/A                                                                     object\n",
      "UNIT                                                                    object\n",
      "SCP                                                                     object\n",
      "STATION                                                                 object\n",
      "LINENAME                                                                object\n",
      "DIVISION                                                                object\n",
      "DATE                                                                    object\n",
      "TIME                                                                    object\n",
      "DESC                                                                    object\n",
      "ENTRIES                                                                 float64\n",
      "EXITS                                                                   float64\n",
      "dtypes: float64(2), object(9)\n",
      "memory usage: 846.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Create initial DataFrame\n",
    "dfs = pd.DataFrame()\n",
    "for file in files:\n",
    "    print(\"Loading {}\".format(str(\"./Data/Turnstile_data/\"+file)))\n",
    "    df = pd.read_csv('./Data/Turnstile_data/' + file)\n",
    "    dfs = dfs.append(df)    \n",
    "\n",
    "dfs.info()  \n",
    "initial_shape = dfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to preprocess data\n",
    "def preprocess(df):\n",
    "    #Standardize column names\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    #Change Time Column to datetime format and round to nearest hour\n",
    "    df['TIME'] = pd.to_datetime(df.TIME, format=\"%H:%M:%S\").dt.round('H')\n",
    "    df['TIME'] = pd.to_datetime(df.TIME, format=\"%H:%M:%S\").dt.time\n",
    "    \n",
    "    #Standardize dates, replace dates not in format MM/DD/YEAR to NaN and remove those rows\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'], format='%m/%d/%Y', errors='coerce')\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    #Create day of week 'DOW' column from data column\n",
    "    dfs['DOW'] = df['DATE'].dt.weekday_name\n",
    "       \n",
    "    #Drop Unncessary columns\n",
    "    df = df.drop(['C/A','UNIT','LINENAME', 'DIVISION', 'DATE'], axis=1)   \n",
    "    \n",
    "    prior_shape = df.shape\n",
    "    \n",
    "    # Remove non 'REGULAR' audits from Desc column \n",
    "    df.drop(df.DESC != 'REGULAR', inplace = True)\n",
    "    \n",
    "    post_shape = df.shape\n",
    "    desc_rows_removed_perc = (prior_shape[0]-post_shape[0]) / prior_shape[0]  * 100\n",
    "\n",
    "    print(\"Percentage of Non Regular Data Removed  = {:08.6f} %\".format(desc_rows_removed_perc))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Non Regular Data Removed  = 0.001038 %\n"
     ]
    }
   ],
   "source": [
    "df = preprocess(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entry and exit data are cumulative, need to adjust to periodic interval counts.\n",
    "df['DIFFS_ENTRIES'] = df['ENTRIES'].diff()\n",
    "df['DIFFS_EXIT'] = df['EXITS'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove turnstile Data in DIFFS_ENTRIES and DIFFS_EXITS that is less than zero and greater than 1e5 (Borderline)\n",
    "negative_diff_entries = df['DIFFS_ENTRIES'] < 0\n",
    "df.loc[negative_diff_entries,'DIFFS_ENTRIES'] = np.nan\n",
    "\n",
    "large_diff_entries =  df['DIFFS_ENTRIES'] > 1e5\n",
    "df.loc[large_diff_entries,'DIFFS_ENTRIES'] = np.nan\n",
    "\n",
    "negative_diff_exits = df['DIFFS_EXIT'] < 0\n",
    "df.loc[negative_diff_exits,'DIFFS_EXIT'] = np.nan\n",
    "\n",
    "large_diff_exits =  df['DIFFS_EXIT'] > 1e5\n",
    "df.loc[large_diff_exits,'DIFFS_EXIT'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Column with Total Number of Individuals Entering and Exiting the Station\n",
    "df['TOTAL_TRAFFIC'] = df['DIFFS_ENTRIES'] + df['DIFFS_EXIT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Unused Data Columns\n",
    "df.drop(['SCP','DESC','ENTRIES', 'EXITS', 'DIFFS_ENTRIES','DIFFS_EXIT'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.38% of the data is not useable'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Percent of data equal to NaN\n",
    "nulls = df['TOTAL_TRAFFIC'].isnull()\n",
    "percent_null = len(df.loc[nulls,'TOTAL_TRAFFIC']) / len(df)\n",
    "f'{percent_null:.2%} of the data is not useable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Rows with NaN Values that are unusable\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assumption\n",
    "#1-Remove Time Between Midnight and 7 am\n",
    "even_am = datetime.time(11,0,0)\n",
    "midnight = datetime.time(0,0,0)\n",
    "df = df.loc[(df.TIME >= even_am) | (df.TIME == midnight)]\n",
    "\n",
    "#df.sort_values(['STATION','TIME', 'DATETIME'], ascending=[True, True, True])\n",
    "#post_shape = df.shape\n",
    "#desc_rows_removed_perc = (1379121-post_shape[0]) / 1379121  * 100\n",
    "\n",
    "#print(\"Percentage of Data Removed  = {:08.6f} %\".format(desc_rows_removed_perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([datetime.time(15, 0), datetime.time(19, 0), datetime.time(23, 0),\n",
       "       datetime.time(11, 0), datetime.time(13, 0), datetime.time(17, 0),\n",
       "       datetime.time(21, 0), datetime.time(12, 0), datetime.time(16, 0),\n",
       "       datetime.time(20, 0), datetime.time(0, 0), datetime.time(14, 0),\n",
       "       datetime.time(18, 0), datetime.time(22, 0)], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.TIME.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
